{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Module Imports\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>var1</th>\n",
       "      <th>var2</th>\n",
       "      <th>var3</th>\n",
       "      <th>var4</th>\n",
       "      <th>var5</th>\n",
       "      <th>var6</th>\n",
       "      <th>var7</th>\n",
       "      <th>var8</th>\n",
       "      <th>var9</th>\n",
       "      <th>var10</th>\n",
       "      <th>var11</th>\n",
       "      <th>var12</th>\n",
       "      <th>var13</th>\n",
       "      <th>var14</th>\n",
       "      <th>var15</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2013</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>-1144.351458</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>6.400000</td>\n",
       "      <td>1067.590514</td>\n",
       "      <td>-10.800000</td>\n",
       "      <td>-6.253469</td>\n",
       "      <td>7</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>0</td>\n",
       "      <td>32.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>-51.596321</td>\n",
       "      <td>1698.073461</td>\n",
       "      <td>20.458846</td>\n",
       "      <td>19.900000</td>\n",
       "      <td>1016.200000</td>\n",
       "      <td>2.947184</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8</td>\n",
       "      <td>89.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2014</td>\n",
       "      <td>6</td>\n",
       "      <td>26</td>\n",
       "      <td>7</td>\n",
       "      <td>-12.059049</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>900.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>24.600000</td>\n",
       "      <td>997.900000</td>\n",
       "      <td>22.300000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>-2.990469</td>\n",
       "      <td>0</td>\n",
       "      <td>154.592918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2016</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>25.723403</td>\n",
       "      <td>12.600000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.800000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>3</td>\n",
       "      <td>1.045986</td>\n",
       "      <td>1</td>\n",
       "      <td>24.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>46.861528</td>\n",
       "      <td>1884.153559</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>6.003678</td>\n",
       "      <td>1010.000000</td>\n",
       "      <td>158.531366</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>11</td>\n",
       "      <td>196.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306863</th>\n",
       "      <td>306863</td>\n",
       "      <td>2015</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>2674.314692</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>12.700000</td>\n",
       "      <td>1010.800000</td>\n",
       "      <td>116.883148</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>5</td>\n",
       "      <td>211.039870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306864</th>\n",
       "      <td>306864</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>67.440307</td>\n",
       "      <td>5500.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>-3.200000</td>\n",
       "      <td>1011.900000</td>\n",
       "      <td>-7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>2</td>\n",
       "      <td>392.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306865</th>\n",
       "      <td>306865</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>2695.833408</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>9.703111</td>\n",
       "      <td>1016.000000</td>\n",
       "      <td>-147.811549</td>\n",
       "      <td>0.176683</td>\n",
       "      <td>8</td>\n",
       "      <td>1.553953</td>\n",
       "      <td>5</td>\n",
       "      <td>245.835549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306866</th>\n",
       "      <td>306866</td>\n",
       "      <td>2016</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>2049.430777</td>\n",
       "      <td>4.665397</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>1014.700000</td>\n",
       "      <td>-7.690267</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>2.100000</td>\n",
       "      <td>1</td>\n",
       "      <td>158.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306867</th>\n",
       "      <td>306867</td>\n",
       "      <td>2016</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>900.000000</td>\n",
       "      <td>163.829802</td>\n",
       "      <td>24.700000</td>\n",
       "      <td>598.497195</td>\n",
       "      <td>-28.811246</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>3</td>\n",
       "      <td>91.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>306868 rows Ã— 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID  var1  var2  var3  var4       var5         var6         var7  \\\n",
       "0            0  2013    12     8    17  11.000000 -1144.351458   500.000000   \n",
       "1            1  2013     5    16     7  17.000000   -51.596321  1698.073461   \n",
       "2            2  2014     6    26     7 -12.059049    45.000000   900.000000   \n",
       "3            3  2016     5    14     7   2.000000    21.000000   300.000000   \n",
       "4            4  2016    10     2    11   2.000000    46.861528  1884.153559   \n",
       "...        ...   ...   ...   ...   ...        ...          ...          ...   \n",
       "306863  306863  2015     4    11     5  17.000000    66.000000  2674.314692   \n",
       "306864  306864  2016     1     3     2  23.000000    67.440307  5500.000000   \n",
       "306865  306865  2017     1    11     9  12.000000    66.000000  2695.833408   \n",
       "306866  306866  2016    12     5     6   9.000000    63.000000  2049.430777   \n",
       "306867  306867  2016     6     7    13   3.000000    23.000000   900.000000   \n",
       "\n",
       "              var8       var9        var10       var11     var12  var13  \\\n",
       "0        45.000000   6.400000  1067.590514  -10.800000 -6.253469      7   \n",
       "1        20.458846  19.900000  1016.200000    2.947184  0.000000      1   \n",
       "2        31.000000  24.600000   997.900000   22.300000  0.000000      7   \n",
       "3        25.723403  12.600000          NaN    9.800000  0.700000      3   \n",
       "4        42.000000   6.003678  1010.000000  158.531366  0.000000      5   \n",
       "...            ...        ...          ...         ...       ...    ...   \n",
       "306863   27.000000  12.700000  1010.800000  116.883148  0.000000      5   \n",
       "306864    2.000000  -3.200000  1011.900000   -7.000000  0.000000      7   \n",
       "306865    6.000000   9.703111  1016.000000 -147.811549  0.176683      8   \n",
       "306866    4.665397   2.800000  1014.700000   -7.690267  0.000000      2   \n",
       "306867  163.829802  24.700000   598.497195  -28.811246  0.000000      9   \n",
       "\n",
       "           var14  var15      target  \n",
       "0       3.700000      0   32.000000  \n",
       "1       1.000000      8   89.000000  \n",
       "2      -2.990469      0  154.592918  \n",
       "3       1.045986      1   24.000000  \n",
       "4       1.800000     11  196.000000  \n",
       "...          ...    ...         ...  \n",
       "306863  0.500000      5  211.039870  \n",
       "306864  1.200000      2  392.000000  \n",
       "306865  1.553953      5  245.835549  \n",
       "306866  2.100000      1  158.000000  \n",
       "306867  2.200000      3   91.000000  \n",
       "\n",
       "[306868 rows x 17 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"var13\"] = df[\"var13\"].astype(\"category\")\n",
    "df[\"var13\"] = df[\"var13\"].cat.codes\n",
    "df[\"var15\"] = df[\"var15\"].astype(\"category\")\n",
    "df[\"var15\"] = df[\"var15\"].cat.codes\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID           0\n",
       "var1         0\n",
       "var2         0\n",
       "var3         0\n",
       "var4         0\n",
       "var5      2960\n",
       "var6      1543\n",
       "var7      1721\n",
       "var8      1278\n",
       "var9      1357\n",
       "var10     1386\n",
       "var11     2515\n",
       "var12     2313\n",
       "var13        0\n",
       "var14     2640\n",
       "var15        0\n",
       "target     735\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         11.000000\n",
       "1         17.000000\n",
       "2        -12.059049\n",
       "3          2.000000\n",
       "4          2.000000\n",
       "            ...    \n",
       "306863    17.000000\n",
       "306864    23.000000\n",
       "306865    12.000000\n",
       "306866     9.000000\n",
       "306867     3.000000\n",
       "Name: var5, Length: 306868, dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for i in [df.var5, df.var6, df.var7, df.var8, df.var9, df.var10, df.var11, df.var12, df.var14]:\n",
    "#     i.fillna(i.median())\n",
    "med_var5 = df.var5.median()\n",
    "# med_var6 = df.var6.median()\n",
    "# med_var7 = df.var7.median()\n",
    "# med_var8 = df.var8.median()\n",
    "# med_var9 = df.var9.median()\n",
    "# med_var10 = df.var10.median()\n",
    "# med_var11 = df.var11.median()\n",
    "# med_var12 = df.var12.median()\n",
    "# med_var14 = df.var14.median()\n",
    "\n",
    "df.var5.fillna(med_var5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID           0\n",
       "var1         0\n",
       "var2         0\n",
       "var3         0\n",
       "var4         0\n",
       "var5      2960\n",
       "var6      1543\n",
       "var7      1721\n",
       "var8      1278\n",
       "var9      1357\n",
       "var10     1386\n",
       "var11     2515\n",
       "var12     2313\n",
       "var13        0\n",
       "var14     2640\n",
       "var15        0\n",
       "target     735\n",
       "dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop(columns= ['target', 'ID'])\n",
    "y = df['target']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size= 0.25, random_state= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "x_train_scaler = scaler.fit_transform(x_train)\n",
    "x_test_scaler = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nPolynomialFeatures does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m lin \u001b[39m=\u001b[39m LinearRegression()\n\u001b[0;32m      2\u001b[0m poly \u001b[39m=\u001b[39m PolynomialFeatures(degree\u001b[39m=\u001b[39m \u001b[39m15\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m x_train_poly \u001b[39m=\u001b[39m poly\u001b[39m.\u001b[39;49mfit_transform(x_train_scaler)\n\u001b[0;32m      5\u001b[0m x_test_poly \u001b[39m=\u001b[39m poly\u001b[39m.\u001b[39mtransform(x_test_scaler)\n\u001b[0;32m      6\u001b[0m poly\u001b[39m.\u001b[39mfit(x_train_poly, y_train)\n",
      "File \u001b[1;32mc:\\Users\\91993\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[0;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 140\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    141\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[0;32m    142\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    143\u001b[0m         return_tuple \u001b[39m=\u001b[39m (\n\u001b[0;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[0;32m    145\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[0;32m    146\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\91993\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:915\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    911\u001b[0m \u001b[39m# non-optimized default implementation; override when a better\u001b[39;00m\n\u001b[0;32m    912\u001b[0m \u001b[39m# method is possible for a given clustering algorithm\u001b[39;00m\n\u001b[0;32m    913\u001b[0m \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    914\u001b[0m     \u001b[39m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[1;32m--> 915\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit(X, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n\u001b[0;32m    916\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    917\u001b[0m     \u001b[39m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[0;32m    918\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32mc:\\Users\\91993\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\91993\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_polynomial.py:322\u001b[0m, in \u001b[0;36mPolynomialFeatures.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    304\u001b[0m \u001b[39m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m    305\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    306\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    307\u001b[0m \u001b[39m    Compute number of output features.\u001b[39;00m\n\u001b[0;32m    308\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    320\u001b[0m \u001b[39m        Fitted transformer.\u001b[39;00m\n\u001b[0;32m    321\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 322\u001b[0m     _, n_features \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(X, accept_sparse\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\u001b[39m.\u001b[39mshape\n\u001b[0;32m    324\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdegree, Integral):\n\u001b[0;32m    325\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdegree \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minclude_bias:\n",
      "File \u001b[1;32mc:\\Users\\91993\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:604\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    602\u001b[0m         out \u001b[39m=\u001b[39m X, y\n\u001b[0;32m    603\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 604\u001b[0m     out \u001b[39m=\u001b[39m check_array(X, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params)\n\u001b[0;32m    605\u001b[0m \u001b[39melif\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_y:\n\u001b[0;32m    606\u001b[0m     out \u001b[39m=\u001b[39m _check_y(y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params)\n",
      "File \u001b[1;32mc:\\Users\\91993\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:959\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    953\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    954\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mFound array with dim \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m expected <= 2.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    955\u001b[0m             \u001b[39m%\u001b[39m (array\u001b[39m.\u001b[39mndim, estimator_name)\n\u001b[0;32m    956\u001b[0m         )\n\u001b[0;32m    958\u001b[0m     \u001b[39mif\u001b[39;00m force_all_finite:\n\u001b[1;32m--> 959\u001b[0m         _assert_all_finite(\n\u001b[0;32m    960\u001b[0m             array,\n\u001b[0;32m    961\u001b[0m             input_name\u001b[39m=\u001b[39;49minput_name,\n\u001b[0;32m    962\u001b[0m             estimator_name\u001b[39m=\u001b[39;49mestimator_name,\n\u001b[0;32m    963\u001b[0m             allow_nan\u001b[39m=\u001b[39;49mforce_all_finite \u001b[39m==\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mallow-nan\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    964\u001b[0m         )\n\u001b[0;32m    966\u001b[0m \u001b[39mif\u001b[39;00m ensure_min_samples \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    967\u001b[0m     n_samples \u001b[39m=\u001b[39m _num_samples(array)\n",
      "File \u001b[1;32mc:\\Users\\91993\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:124\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[39mif\u001b[39;00m first_pass_isfinite:\n\u001b[0;32m    122\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m--> 124\u001b[0m _assert_all_finite_element_wise(\n\u001b[0;32m    125\u001b[0m     X,\n\u001b[0;32m    126\u001b[0m     xp\u001b[39m=\u001b[39;49mxp,\n\u001b[0;32m    127\u001b[0m     allow_nan\u001b[39m=\u001b[39;49mallow_nan,\n\u001b[0;32m    128\u001b[0m     msg_dtype\u001b[39m=\u001b[39;49mmsg_dtype,\n\u001b[0;32m    129\u001b[0m     estimator_name\u001b[39m=\u001b[39;49mestimator_name,\n\u001b[0;32m    130\u001b[0m     input_name\u001b[39m=\u001b[39;49minput_name,\n\u001b[0;32m    131\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\91993\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:173\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[1;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[39mif\u001b[39;00m estimator_name \u001b[39mand\u001b[39;00m input_name \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m has_nan_error:\n\u001b[0;32m    157\u001b[0m     \u001b[39m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[0;32m    158\u001b[0m     \u001b[39m# scikit-learn.\u001b[39;00m\n\u001b[0;32m    159\u001b[0m     msg_err \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\n\u001b[0;32m    160\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m does not accept missing values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    161\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    171\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m#estimators-that-handle-nan-values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    172\u001b[0m     )\n\u001b[1;32m--> 173\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[1;31mValueError\u001b[0m: Input X contains NaN.\nPolynomialFeatures does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "lin = LinearRegression()\n",
    "poly = PolynomialFeatures(degree= 15)\n",
    "\n",
    "x_train_poly = poly.fit_transform(x_train_scaler)\n",
    "x_test_poly = poly.transform(x_test_scaler)\n",
    "poly.fit(x_train_poly, y_train)\n",
    "lin.fit(x_train_poly, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
